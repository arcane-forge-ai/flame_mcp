! This helm chart is fully generated by AI and reviewed by developers.

# Flame MCP Server Helm Chart

This Helm chart deploys the Flame MCP (Model Context Protocol) Server on Kubernetes, providing semantic search capabilities over Flame engine documentation.

## Prerequisites

- Kubernetes 1.19+
- Helm 3.0+
- Azure OpenAI service access
- Qdrant vector database (can be deployed separately)

## Installation

### Add Required Secrets

Before installing, you need to create the required secrets:

```bash
# Create a values override file
cat > values-override.yaml << EOF
secrets:
  openai:
    apiKey: "your-azure-openai-api-key"
    apiBase: "https://your-resource.openai.azure.com/"
  qdrant:
    token: "your-qdrant-token"  # Optional if Qdrant has no auth
EOF
```

### Install the Chart

```bash
# Install with default values
helm install flame-mcp-server ./helm

# Install with custom values
helm install flame-mcp-server ./helm -f values-override.yaml

# Install with inline values
helm install flame-mcp-server ./helm \
  --set secrets.openai.apiKey="your-api-key" \
  --set secrets.openai.apiBase="https://your-resource.openai.azure.com/" \
  --set config.qdrant.host="http://your-qdrant-host"
```

## Configuration

The following table lists the configurable parameters and their default values:

### Image Configuration
| Parameter | Description | Default |
|-----------|-------------|---------|
| `image.repository` | Container image repository | `flame-mcp-server` |
| `image.tag` | Container image tag | `latest` |
| `image.pullPolicy` | Image pull policy | `IfNotPresent` |

### Application Configuration
| Parameter | Description | Default |
|-----------|-------------|---------|
| `replicaCount` | Number of replicas | `2` |
| `config.qdrant.host` | Qdrant host URL | `http://qdrant-service` |
| `config.qdrant.port` | Qdrant port | `6333` |
| `config.collection.name` | Qdrant collection name | `flame_docs` |
| `config.openai.apiVersion` | Azure OpenAI API version | `2024-02-01` |
| `config.openai.modelName` | OpenAI embedding model | `text-embedding-3-small` |

### Security Configuration
| Parameter | Description | Default |
|-----------|-------------|---------|
| `secrets.openai.apiKey` | Azure OpenAI API key | `""` |
| `secrets.openai.apiBase` | Azure OpenAI endpoint | `""` |
| `secrets.qdrant.token` | Qdrant authentication token | `""` |

### Resource Configuration
| Parameter | Description | Default |
|-----------|-------------|---------|
| `resources.requests.cpu` | CPU request | `100m` |
| `resources.requests.memory` | Memory request | `256Mi` |
| `resources.limits.cpu` | CPU limit | `500m` |
| `resources.limits.memory` | Memory limit | `512Mi` |

### Autoscaling Configuration
| Parameter | Description | Default |
|-----------|-------------|---------|
| `autoscaling.enabled` | Enable HPA | `false` |
| `autoscaling.minReplicas` | Minimum replicas | `2` |
| `autoscaling.maxReplicas` | Maximum replicas | `10` |
| `autoscaling.targetCPUUtilizationPercentage` | Target CPU % | `80` |

### Ingress Configuration
| Parameter | Description | Default |
|-----------|-------------|---------|
| `ingress.enabled` | Enable ingress | `false` |
| `ingress.className` | Ingress class name | `""` |
| `ingress.hosts[0].host` | Hostname | `flame-mcp.local` |

## Usage Examples

### Basic Deployment
```bash
helm install my-flame-mcp ./helm \
  --set secrets.openai.apiKey="sk-..." \
  --set secrets.openai.apiBase="https://my-resource.openai.azure.com/"
```

### With Custom Qdrant
```bash
helm install my-flame-mcp ./helm \
  --set config.qdrant.host="http://my-qdrant.example.com" \
  --set config.qdrant.port="6333" \
  --set secrets.openai.apiKey="sk-..."
```

### With Ingress Enabled
```bash
helm install my-flame-mcp ./helm \
  --set ingress.enabled=true \
  --set ingress.hosts[0].host="flame-mcp.mydomain.com" \
  --set secrets.openai.apiKey="sk-..."
```

### With Autoscaling
```bash
helm install my-flame-mcp ./helm \
  --set autoscaling.enabled=true \
  --set autoscaling.minReplicas=3 \
  --set autoscaling.maxReplicas=20 \
  --set secrets.openai.apiKey="sk-..."
```

## Monitoring and Health Checks

The application provides a health check endpoint at `/health` which is used for:
- Kubernetes liveness probe
- Kubernetes readiness probe
- Load balancer health checks

## Upgrading

```bash
# Upgrade to a new version
helm upgrade flame-mcp-server ./helm

# Upgrade with new values
helm upgrade flame-mcp-server ./helm -f new-values.yaml
```

## Uninstallation

```bash
helm uninstall flame-mcp-server
```

## Troubleshooting

### Common Issues

1. **Pod not starting**
   - Check if secrets are properly configured
   - Verify Qdrant connectivity
   - Check resource limits

2. **Health check failures**
   - Ensure `/health` endpoint is accessible
   - Check application logs
   - Verify external dependencies (Azure OpenAI, Qdrant)

3. **Authentication errors**
   - Verify Azure OpenAI API key and endpoint
   - Check Qdrant authentication if enabled

### Debugging Commands

```bash
# Check pod status
kubectl get pods -l app.kubernetes.io/name=flame-mcp-server

# View logs
kubectl logs -l app.kubernetes.io/name=flame-mcp-server

# Check configuration
kubectl describe configmap <release-name>-config
kubectl describe secret <release-name>-secret

# Test health endpoint
kubectl port-forward svc/<release-name> 8000:8000
curl http://localhost:8000/health
``` 